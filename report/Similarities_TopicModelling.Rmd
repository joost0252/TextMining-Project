---
output:
  html_document: default
  pdf_document: default
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
source("../scripts/setup.R")
```

# Part 3.3.1 : Topic Modelling 

## Similarities between season scripts
In this part, we want to compare the similarities of the scripts between the season. We decided to use the 3 similarities measure to compute the similarity matrix: Jaccard similarity, Cosine distance, and Euclidean distance. The best/explanatory method in our case seems to be the Euclidean one and we will therefore concentrate on it for the following.

```{r echo=FALSE}
#season.jac <- textstat_simil(
  #season.tfidf_lemma,
  #method = "jaccard",
  #margin = "documents")

#season.cos <- textstat_simil(
  #season.tfidf_lemma,
  #method = "cosine",
  #margin = "documents")

season.euc <- textstat_dist(
  season.tfidf_lemma,
  method = "euclidean",
  margin = "documents")
```

```{r echo=FALSE}
## Jaccard 
#season.jac.mat <- melt(as.matrix(season.jac)) # Convert the object to matrix then to data frame 
#ggplot(data = season.jac.mat, 
       #mapping = aes(x = Var1, y = Var2, fill = value)) +
  #scale_fill_gradient2(
    #low = "blue",
    #high = "red",
    #mid = "white", 
    #midpoint = 0.5,
    #limit = c(0, 1),
    #name = "Jaccard") +
  #geom_tile() + xlab("") + ylab("")

## Cosine
#season.cos.mat <- melt(as.matrix(season.cos))
#ggplot(
  #data = season.cos.mat,
  #mapping = aes(x = Var1, y = Var2, fill = value)) +
  #scale_fill_gradient2(
    #low = "blue",
    #high = "red",
    #mid = "white",
    #midpoint = 0.5,
    #limit = c(0, 1),
    #name = "Cosine") +
  #geom_tile() + xlab("") + ylab("")

## Euclidean
season.euc.mat <- melt(as.matrix(season.euc))
M <- max(season.euc.mat$value) # maximum distance
season.euc.mat$value.std <- (M - season.euc.mat$value)/M 
# conversion from distance to similarity in [0,1]
ggplot(
  data = season.euc.mat,
  mapping = aes(x = Var1, 
                y = Var2,
                fill = value.std)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white", 
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Euclidean") +
  geom_tile() + xlab("") + ylab("")
```
From the Euclidean co-occurence matrix plot, it seems that season 4 is very far away to every other seasons. On the contrary, season 6 and season 2 are quite distant (but we know that there may be a problem in webscrapping).

## Clustering 
Then, to create a cluster, we decide to focus on the Euclidean distance only.

```{r echo=FALSE}
season.hc <- hclust(as.dist(season.euc))
## crude.hc <- hclust(as.dist(1 - crude.jac)) # use this line for Jaccard
## crude.hc <- hclust(as.dist(1 - crude.cos)) # use this line for Cosine
plot(season.hc)

season.clust <- cutree(season.hc, k = 3)
season.clust

season.km <- kmeans(season.tfidf_lemma, centers = 3)
season.km$cluster


data.frame(
  Clust.1 = names(sort(apply(season.tfidf[season.clust==1, ], 2, sum), decreasing = TRUE)[1:5]),
  Clust.2 = names(sort(apply(season.tfidf[season.clust==2, ], 2, sum), decreasing = TRUE)[1:5]),
  Clust.3 = names(sort(apply(season.tfidf[season.clust==3, ], 2, sum), decreasing = TRUE)[1:5])
)
```
Not surprisingly here, we find the same characteristics for seasons 4, 2 and 6 as before regarding their proximities.

## Similarities between words
We use the cosine distance measure to determine the similarities between words. 
#(Euclidean doesn't work and jaccard is very similar so idk which one to take ? + Not useful)
```{r echo=FALSE, include=FALSE}
# Cosine
season.feat <- textstat_frequency(season.dfm_lemma) %>%
  filter(rank <= 50) 
season.feat$feature

season.cos <- textstat_simil(
  season.dfm_lemma[, season.feat$feature],
  method = "cosine",
  margin = "feature")

season.cos.mat <- melt(as.matrix(season.cos)) # Convert the object to matrix then to data frame 

ggplot(data = season.cos.mat, aes(x=Var1, y=Var2, fill=value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Cosine") +
  geom_tile() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
    axis.text.y = element_text(size = 5)) +
  xlab("") + 
  ylab("")


# Jaccard
#season.feat2 <- textstat_frequency(season.dfm_lemma) %>%
  #filter(rank <= 50) 
#season.feat$feature

#season.jac <- textstat_simil(
  #season.dfm_lemma[, season.feat$feature],
  #method = "jaccard",
  #margin = "feature")

#season.jac.mat <- melt(as.matrix(season.euc)) # Convert the object to matrix then to data frame 

#ggplot(data = season.jac.mat, aes(x=Var1, y=Var2, fill=value)) +
  #scale_fill_gradient2(
    #low = "blue",
    #high = "red",
    #mid = "white",
    #midpoint = 0.5,
    #limit = c(0, 1),
    #name = "jaccard") +
  #geom_tile() + 
  #theme(
    #axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
    #axis.text.y = element_text(size = 5)) +
  #xlab("") + 
  #ylab("")
  
# Cosine
#season.feat <- textstat_frequency(season.tf) %>%
  #filter(rank <= 40) 
#season.feat$feature

#season.cos <- textstat_simil(
  #season.tf[, season.feat$feature],
  #method = "cosine",
  #margin = "feature")
#season.cos.mat <- melt(as.matrix(season.cos)) # Convert the object to matrix then to data frame 

#ggplot(data = season.cos.mat, aes(x=Var1, y=Var2, fill=value)) +
  #scale_fill_gradient2(
    #low = "blue",
    #high = "red",
    #mid = "white",
    #midpoint = 0.5,
    #limit = c(0, 1),
    #name = "Cosine") +
  #geom_tile() + 
  #theme(
    #axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
    #axis.text.y = element_text(size = 5)) +
  #xlab("") + 
  #ylab("")
```

## Clustering words
```{r echo=FALSE}
season.hcw <- hclust(as.dist(1 - season.cos))
plot(season.hcw)
```


## Part 3.3.2 : Term-Topic Analysis

We want to analyze the topics of the season scripts using LSA and LDA.

# Maybe we can put in into include = FALSE
```{r echo=FALSE}
season.tf <- dfm(season.tk_lemma)
season.lsa <- textmodel_lsa(x = season.tf, nd = 10) 
head(season.lsa$docs)
head(season.lsa$features)
head(season.lsa$sk)
```

```{r echo=FALSE, include=FALSE}
season.freq_lemma <- ntoken(season.tk_lemma)  
data.frame(season.freq_lemma,
           dim1 = season.lsa$docs[, 1]) %>% 
  ggplot(aes(season.freq_lemma, dim1)) + 
  geom_point() + 
  xlab("Number of tokens") + 
  ylab("LSA dim. 1")
```
As the first dimension is often linked to the document length, we wanted to verify that this was the case. And indeed, the dimension 1 is negatively correlated with the document length.

Then we did an analysis of topics 2 and 3.
```{r echo=FALSE, include=FALSE}
n.terms <- 5
## For Dimension 2
w.order <- sort(season.lsa$features[, 2], decreasing = TRUE)
w.top2 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))
## For Dimension 3
w.order <- sort(season.lsa$features[,3], decreasing = TRUE)
w.top3 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))

# Topic 2
w.top2
# Topic 3
w.top3
```
- Topic 2 is associated positively to "baby", "feel" and "love" and negatively with "ring", "night" and "mother".
- Topic 3 is associated positively to "time", "gablehouser" and "enter" and negatively with "ring", "past" and "feel".

In order to visually represent the relationship between topics 2 and 3, seasons and words, we perform an LSA-based biplot. Because of the large number of terms, the interpretation is difficult. Below, you can see the chart to the terms that are mostly related to the dimensions 2 and 3
```{r echo=FALSE, include=FALSE}
biplot(
  y = season.lsa$docs[, 2:3],
  x = season.lsa$features[, 2:3],
  col = c("black", "red"),
  cex = c(0.3, 0.3),
  xlab = "Dim 2",
  ylab = "Dim 3")
```

```{r echo=FALSE}
w.subset <- 
  season.lsa$features[
    c(unique(c(names(w.top2), names(w.top3)))), 2:3]
biplot(
  y = season.lsa$docs[, 2:3],
  x = w.subset,
  col = c("black","red"),
  cex = c(0.5, 0.5),
  xlab = "Dim 2",
  ylab = "Dim 3")
```
The biplot shows that Topic 2 is associated with seasons 7,8,9 and 10 and with the words “love”, “baby”, “happy","guy" and anti-associated with season 3 and with the words “ring”, “friend”, “mother”. Topic 3 is associated with seasons 1 and 4 and with words “enter”, “gablehouser”, “machine” and anti-associated with “ring”, “fine”, “day”. 

## LDA using quanteda
We now turn to an LDA. We started with 10 topics and then eliminated the non-miningful ones until we get to choose 5 topics. These topics are related to the words below. 
```{r echo=FALSE}
set.seed(1234) #To create reproducible results
season.lda <- textmodel_lda(x = season.tf, k = 5)
seededlda::terms(season.lda, 5)
```
# I think we can remove this one since we have the graph juste after
```{r echo=FALSE}
seededlda::topics(season.lda)
seededlda::topics(season.lda) %>% table()
```
## Term-Topic Analysis
The "phi" provides the probabilities of selecting a term given that it is a given topic. For a given topic, the largest phi provide the terms that are most associated with the topic.
```{r echo=FALSE}
phi.long <- melt(
  season.lda$phi,
  varnames = c("Topic", "Term"),
  value.name = "Phi") 

phi.long %>% 
  group_by(Topic) %>% 
  top_n(5, Phi) %>% 
  ggplot(aes(reorder_within(Term, Phi, Topic), Phi)) + 
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ Topic, scales = "free_y") +
  scale_x_reordered() + 
  xlab("Term") + 
  theme(
    axis.text.y = element_text(size = 5),
    strip.text = element_text(size = 5))
```
Here we plot the 5 largest probability terms within each subject. Despite the fact that these terms have the ighest probability to appears in this topic, their phi values are relatively low and therefore they are only slightly more common than the other terms.

## Topic-Document Analysis
The "theta" provides the probabilities (i.e., proportions) of the topics within each document (season). 
```{r echo=FALSE}
set.seed(1234)
theta.long <- melt(
  season.lda$theta,
  varnames = c("Doc", "Topic"),
  value.name = "Theta")

theta.long %>% 
  group_by(Topic) %>% 
  top_n(10, Theta) %>% 
  ggplot(aes(reorder_within(Doc, Theta, Topic), Theta)) + 
  geom_col(show.legend = FALSE) +
  coord_flip()+
  facet_wrap(~ Topic, scales = "free_y") +
  scale_x_reordered() + 
  xlab("Document") + 
  theme(
    axis.text.y = element_text(size = 5),
    strip.text = element_text(size = 5))
```
This graph shows us that Topic 5 is present at more than 50% in all seasons. Topic 1 is more related to season 4, Topic 2 to seasons 1,2,3, Topic 3 to seasons 5,6,8 and Topic 4 to seasons 9 and 10. It seems to be a chronological link between the topics and the seasons.





