---
output:
  html_document: default
  pdf_document: default
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
source("../scripts/setup.R")
```

### Sentiment Analysis

## 1.Dictionary-based analysis
```{r}
library(tidyverse)
library(tidytext)
library(readr)
library(sentimentr)
library(quanteda)
library(quanteda.textstats)
library(lexicon) 
library(flextable)

library(tidytext) # contains stop_words
library(reshape2)
library(ggplot2)
library(dplyr)
```

#################################### Season Analysis ##################################################

### Sentiment Analysis

## 1.Dictionary-based analysis

# NRC dictionary
```{r}
get_sentiments(lexicon = "nrc")
```
>>>>>>> 4d4d182196e25bfe573d70e2954ffc6ea1170f2a

We join the corresponding sentiment qualifier in “nrc” using inner.join() from dplyr:
```{r}
season.tb <- as_tibble(
  data.frame(
    season_scripts))

season.tok <- unnest_tokens(
  season.tb,
  output = "word",
  input = "agg_script",
  to_lower = TRUE,
  strip_punct = TRUE,
  strip_numeric = TRUE)

season.sent <- 
  inner_join(
    season.tok,
    get_sentiments("nrc"),
    by = c("word" = "word"))
head(season.sent, 10) %>% flextable() %>% autofit()
```

Summary (long format)
```{r}
table(season.sent$season, 
      season.sent$sentiment)

## Long format + barplots --> NOT WORKING
season.sent %>% 
  group_by(season, sentiment) %>% 
  summarize(n = n()) %>%
  ungroup() %>% 
  ggplot(aes(x = sentiment,
             y = n,
             fill = sentiment)) + 
  geom_bar(stat = "identity",
           alpha = 0.8) + 
  facet_wrap(~ season ) + 
  coord_flip()
```

To compare the documents, we rescale them by their length (i.e. the frequencies of sentiments are computed, by document):
```{r}
#totals by document
season.sent.doc.total <- 
  season.sent %>% 
  group_by(season) %>% 
  summarize(Total = n()) %>% 
  ungroup()

#add totals and compute relative frequency
left_join(
  season.sent,
  season.sent.doc.total
  ) %>% 
  group_by(season, sentiment) %>%  
  summarize(n = n(),
            Total = unique(Total)) %>%
  ungroup() %>% 
  mutate(relfreq = n / Total) %>%
  ggplot(aes(
    x = sentiment,
    y = relfreq,
    fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ season) + 
  coord_flip()
```


## 2. Value-Based analysis ("afinn" dictionary)
```{r}
get_sentiments("afinn")
```

```{r}
season.sent <-
  inner_join(
    season.tok, 
    get_sentiments("afinn"),
    by = c("word" = "word"))

## Summarize per document (value average) + barplot
season.sent %>% 
  group_by(season) %>% 
  summarize(Score = mean(value)) %>% 
  ungroup() %>% 
  arrange(Score) %>% 
  flextable() %>% 
  autofit()
```

```{r}
season.sent %>% 
  group_by(season) %>% 
  summarize(Score = mean(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = reorder(season, Score), y = Score)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  ylab("Mean Sentiment Score") +
  xlab("")
```
## Quanteda analysis
```{r}
summary(season.cp)

tokens_lookup(
  season.tk,
  dictionary = data_dictionary_LSD2015
  ) 

season.sent1 <- tokens_lookup(
  season.tk, 
  dictionary = data_dictionary_LSD2015) %>% 
  dfm() %>% 
  tidy()
season.sent1 %>% 
  pivot_wider(
    names_from = "term",
    values_from = "count"
  ) %>% 
  mutate(negative = replace_na(negative, 0),
         Score = round(negative / (negative + positive), 3)) %>% 
  arrange(Score) %>% 
  head(20) %>% 
  flextable() %>% 
  autofit() 
```

```{r}
ggplot(season.sent1,
       aes(x = document,
           y = count,
           fill = term)) + 
  geom_bar(stat="identity") + 
  coord_flip()
```

## Valence-Shifters analysis

```{r}
hash_sentiment_jockers_rinker
hash_valence_shifters
```

```{r}
# Very long time to execute
#mytext <- get_sentences(season_scripts$agg_script)
#mytext
```


```{r}
# Same
#sentiment(mytext) %>% 
  #flextable() %>% 
  #autofit()
```

### Analysis by character --> Doesn't work

```{r}
tidy_nrc %>% 
  filter(author %in% c("sheldon","leonard","penny","howard","raj")) %>% 
  ggplot(aes(sentiment, fill = author))+
  geom_bar(show.legend = FALSE)+
  facet_wrap(author~.)+
  theme_dark()+
  theme(
    strip.text = element_text(face = "bold"),
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
  )+
  labs(fill = NULL, x = NULL, y = "Sentiment Frequency", title = "Sentiments of each characters by using nrc lexicon")+
  scale_fill_manual(values = c("#EA181E", "#00B4E8", "#FABE0F","#EA181E", "#00B4E8", "#FABE0F"))+
  annotation_custom(img,ymax = 4000, ymin = 2000, xmin = 1, xmax = 5)
```

## Similarities between season scripts
```{r}
season.dfm <- dfm(season.tk)
season.tfidf <- dfm_tfidf(season.dfm)

season.jac <- textstat_simil(
  season.tfidf,
  method = "jaccard",
  margin = "documents")

season.cos <- textstat_simil(
  season.tfidf,
  method = "cosine",
  margin = "documents")

season.euc <- textstat_dist(
  season.tfidf,
  method = "euclidean",
  margin = "documents")
```

```{r}
## Jaccard 
season.jac.mat <- melt(as.matrix(season.jac)) # Convert the object to matrix then to data frame 
ggplot(data = season.jac.mat, 
       mapping = aes(x = Var1, y = Var2, fill = value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white", 
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Jaccard") +
  geom_tile() + xlab("") + ylab("")

## Cosine
season.cos.mat <- melt(as.matrix(season.cos))
ggplot(
  data = season.cos.mat,
  mapping = aes(x = Var1, y = Var2, fill = value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Cosine") +
  geom_tile() + xlab("") + ylab("")

## Euclidean
season.euc.mat <- melt(as.matrix(season.euc))
M <- max(season.euc.mat$value) # maximum distance
season.euc.mat$value.std <- (M - season.euc.mat$value)/M 
# conversion from distance to similarity in [0,1]
ggplot(
  data = season.euc.mat,
  mapping = aes(x = Var1, 
                y = Var2,
                fill = value.std)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white", 
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Euclidean") +
  geom_tile() + xlab("") + ylab("")
```

## Clustering 
```{r}
season.hc <- hclust(as.dist(season.euc))
## crude.hc <- hclust(as.dist(1 - crude.jac)) # use this line for Jaccard
## crude.hc <- hclust(as.dist(1 - crude.cos)) # use this line for Cosine
plot(season.hc)

season.clust <- cutree(season.hc, k = 3)
season.clust

season.km <- kmeans(season.tfidf, centers = 3)
season.km$cluster


data.frame(
  Clust.1 = names(sort(apply(season.tfidf[season.clust==1, ], 2, sum), decreasing = TRUE)[1:5]),
  Clust.2 = names(sort(apply(season.tfidf[season.clust==2, ], 2, sum), decreasing = TRUE)[1:5]),
  Clust.3 = names(sort(apply(season.tfidf[season.clust==3, ], 2, sum), decreasing = TRUE)[1:5])
)


data.frame(
  Clust.1 = names(sort(apply(season.tfidf[season.km$cluster==1,], 2, sum), decreasing = TRUE)[1:5]),
  Clust.2 = names(sort(apply(season.tfidf[season.km$cluster==2,], 2, sum), decreasing = TRUE)[1:5]),
  Clust.3 = names(sort(apply(season.tfidf[season.km$cluster==3,], 2, sum), decreasing = TRUE)[1:5])
)
```


## Similarities between words
```{r}
season.feat <- textstat_frequency(season.dfm) %>%
  filter(rank <= 40) 
season.feat$feature

season.cos <- textstat_simil(
  season.dfm[, season.feat$feature],
  method = "cosine",
  margin = "feature")
season.cos.mat <- melt(as.matrix(season.cos)) # Convert the object to matrix then to data frame 

ggplot(data = season.cos.mat, aes(x=Var1, y=Var2, fill=value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Cosine") +
  geom_tile() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
    axis.text.y = element_text(size = 5)) +
  xlab("") + 
  ylab("")

```

## Clustering words
```{r}
season.hcw <- hclust(as.dist(1 - season.cos))
plot(season.hcw)
```

## Co-occurences --> Doesn't work
```{r}
season.fcm <- fcm(season.tk, 
                 window = 3, 
                 tri = FALSE)
season.fcm <- (season.fcm + t(season.fcm))/2 ## make the co-occurrence matrix symmetrical

season.fcm.mat <- melt(
  as.matrix(
    season.fcm[season.feat$feature, season.feat$feature]),
  varnames = c("Var1", "Var2")) 
ggplot(data = season.fcm.mat, 
       mapping = aes(x = Var1, y = Var2, fill = value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 140,
    limit = c(0, 280),
    name = "Co-occurrence") +
  geom_tile() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
        axis.text.y = element_text(size = 5)) +
  xlab("") +
  ylab("")
```

## Cluster dendrogram
```{r}
season.inv_occ <- 
  280 - as.matrix(
    season.fcm[season.feat$feature, season.feat$feature]) ## 280 is the max co-occurrence here
season.hc <- hclust(as.dist(season.inv_occ))
plot(season.hc)
```


