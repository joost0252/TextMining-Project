---
output:
  html_document: default
  pdf_document: default
---
```{r, echo = FALSE, message = FALSE, warning = FALSE}
source("../scripts/setup.R")
```

# First Data Structuring


```{r, echo = FALSE, message = FALSE, warning = FALSE}
script.tb <- as_tibble(
  data.frame(data_scripts)
  )
View(script.tb)

script.tok <- unnest_tokens(
  tbl = script.tb, 
  output = "word",
  input = "script",
  to_lower = TRUE,
  strip_punct = TRUE, 
  strip_numeric = TRUE)

script.tok <- anti_join(
  script.tok,
  stop_words,
  by = c("word" = "word")
)
head(script.tok, 10)

```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(udpipe)
script.for.udpipe <- 
  script.tb
script.for.udpipe <- script.for.udpipe %>% 
  rename(doc_id = document,
         text = script)

script.fr <- script.tok %>% 
  group_by(word) %>% 
  summarize(n = n()) %>%
  arrange(desc(n))

script.fr <- script.tok %>% 
  group_by(document, word) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  arrange(desc(n))

script.tfidf <- script.fr %>%  
  bind_tf_idf(term = word,
              document = document,
              n = n) %>%
  arrange(desc(n))
head(script.tfidf, n = 10) %>% flextable() %>% autofit()

script.tfidf.max <- script.tfidf %>% 
  group_by(word) %>% 
  summarise(tf_idf = max(tf_idf)) %>% 
  ungroup() %>% arrange(desc(tf_idf))
head(script.tfidf.max, n = 10) %>% flextable() %>% autofit()

script.cp <- VCorpus(VectorSource(data_scripts$script))
## inspect(crude.cp[[2]]) # un-comment this line

script.cp <- tm_map(script.cp, removePunctuation) 
script.cp <- tm_map(script.cp, removeNumbers)
script.cp <- tm_map(script.cp, removeWords, stopwords("english"))
script.cp <- tm_map(script.cp, content_transformer(tolower))
script.cp <- tm_map(script.cp, stripWhitespace)
script.cp <- tm_map(script.cp, removeWords, "reuter")



```

## DTM matrix 
```{r}
script.dtm <- DocumentTermMatrix(script.cp)
inspect(script.dtm)


```

```{r}
script.tfidf <- DocumentTermMatrix(script.cp, 
                 control = list(weighting = weightTfIdf))
inspect(script.tfidf)
```



#EDA

```{r echo=FALSE}
## Libraries needed for the exercises
library(readr)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(tidytext)
library(dplyr)
library(ggplot2)
library(broom)
library(ggwordcloud)
library(igraph)
```

```{r echo=FALSE}

script.cp <- corpus(data_scripts$script)
script.tk <- tokens(
  script.cp,
  remove_numbers = TRUE,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_separators = TRUE
  )
script.tk <- script.tk %>% 
  tokens_tolower() %>% 
  tokens_remove(stop_words$word) %>% 
  tokens_remove(c("sheldon","leonard","penny","howard","raj"))
# We can see the main characters that are Sheldon, Leonard, Penny, Howard and Raj. They appear in all the sesaons's espisods.
# We will remove their name for the following explanatory data analysis because otherwise it will biaise our results.


## Compute the DTM, TF-IDF and global frequencies
script.dfm <- dfm(script.tk)
script.tfidf <- dfm_tfidf(script.dfm)  
script.freq <- textstat_frequency(script.dfm)


script.freq %>% 
  top_n(40, frequency) %>%
  ggplot(aes(
    x = reorder(feature, frequency),
    y = frequency)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Frequency") + 
  ylab("term")
```

```{r echo=FALSE}
textplot_wordcloud(script.dfm)
```

```{r echo=FALSE}
script.dfm %>% 
  tidy() %>% 
  top_n(10, count) %>% 
  ggplot(aes(x = term, y = count)) + 
  geom_bar(stat = "Identity") + 
  coord_flip() +
  theme(axis.text.y = element_text(size = 3.5),
        axis.ticks.y = element_blank())  + 
  facet_wrap(~document, ncol = 2)
```
