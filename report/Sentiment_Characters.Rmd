---
output:
  html_document: default
  pdf_document: default
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
source("../scripts/setup.R")
```

####################################### Sentiment Analysis by Characters ###############################################

```{r}
char.cp <- corpus(character_speech$character_scripts)

char.tk <- tokens(
  char.cp,
  remove_numbers = TRUE, 
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_separators = TRUE)


#Remove possessive apostrophe ('s), such that words as Leonard's are not skipped in the next part of the code
char.tk <- tokens_replace(
    char.tk, 
    types(char.tk),
    stringi::stri_replace_all_regex(types(char.tk), "['\\p{Pf}][s]", ""))


words_to_remove <- c("scene", "series", "episode","pilot", "yeah","uh","hey",
                    "gonna","knock","dr","apartment","um","wanna","door","Time shift","corridor")

characters_names <- c("sheldon","leonard","penny","howard","raj", "amy", 
                      "bernadette", "emily", "cooper", "stuart", "lucy",
                      "arthur","rostenkowski","bert","mike","james","lorvis",
                      "dan","dr","beverly","isabella","williams","lesley",
                      "missy","dave","claire","meemaw", "mary","leslie","lalita",
                      "dennis","alfred", "susan", "ramona", "christie","gallo",
                      "zack", "wil", "kurt","toby", "amelia","nathan",
                      "beverley","haley","mandy","adam","barry","mark","rebecca","randall",
                      "colonel","priya","Elizabeth","Katee","halley","alice","stan","valentine",
                      "jimmy","wyatt","kim","koothrapalli")

char.tk <- char.tk %>% 
  tokens_tolower() %>%
  tokens_remove(stop_words$word) %>%
  tokens_remove(c(characters_names, words_to_remove)) 

char.tk <- tokens_replace(char.tk,
  pattern = hash_lemmas$token,
  replacement = hash_lemmas$lemma)

## Compute the DTM
char.dfm <- dfm(char.tk)

## Compute the TF-IDF 
char.tfidf <- dfm_tfidf(char.dfm)  

## Compute the global frequencies
char.freq <- textstat_frequency(char.dfm)
```

```{r echo=FALSE}
char.dfm %>% 
  tidy() %>% 
  top_n(10, count) %>% 
  ggplot(aes(x = term, y = count)) + 
  geom_bar(stat = "Identity") + 
  coord_flip() +
  theme(axis.text.y = element_text(size = 5),
        axis.ticks.y = element_blank())  + 
  facet_wrap( ~character_speech$character_name, ncol = 2) + 
  ggtitle("Top 10 TF per character")
```

```{r}
char.tb <- as_tibble(data.frame(character_speech))

char.tk <- unnest_tokens(
  char.tb,
  output = "word",
  input = "character_scripts",
  to_lower = TRUE,
  strip_punct = TRUE,
  strip_numeric = TRUE)
 
char.tk <- char.tk %>%
  anti_join(stop_words, by = c("word" = "word"))
  
char.sent <- 
  inner_join(
    char.tk,
    get_sentiments("nrc"),
    by = c("word" = "word"))

head(char.sent, 10) %>% 
  flextable() %>%
  autofit()

```

```{r}
## Long format
char.sent %>% 
  group_by(character_name, sentiment) %>% 
  summarize(n = n()) %>%
  ungroup() %>% 
  ggplot(aes(x = sentiment,
             y = n,
             fill = sentiment)) + 
  geom_bar(stat = "identity",
           alpha = 0.8) + 
  facet_wrap(~character_name) + 
  coord_flip()
```

```{r echo=FALSE}
char.dfm %>% textstat_lexdiv()

char.dfm %>% textstat_lexdiv() %>%
  arrange(desc(TTR)) %>%
  slice(1:10) %>% #plot only the top 10
  ggplot(aes(reorder(document, -TTR),
             TTR)) + 
  geom_bar(stat = "identity") + 
  xlab("character_name") + 
  ggtitle("Plot of the 10 top Token-Type-Ratio") 
```


## Sentiments of each characters by using nrc lexicon 

```{r}
char.sent %>% 
  group_by(character_name) %>% 
  ggplot(aes(sentiment, fill = character_name)) +
  geom_bar(show.legend = FALSE) +
  facet_wrap(character_name~.) +
  theme_dark() +
  theme(
    strip.text = element_text(face = "bold"),
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
  ) +
  labs(fill = NULL, 
       x = NULL, 
       y = "Sentiment Frequency", 
       title = "Sentiments of each characters by using nrc lexicon") +
  scale_fill_manual(values = c( "chartreuse1", "#FABE0F","cyan3", "darkorchid3", "palevioletred1"))
```

## Negative-Positive Ratio in all seasons by using bing lexicon
```{r echo=FALSE, include=FALSE}
head(get_sentiments(lexicon = "bing"))
```

```{r}
char.sent2 <-
  inner_join(
    char.tk, 
    get_sentiments("bing"),
    by = c("word" = "word"))

char.sent2 %>% 
  group_by(character_name) %>% 
  group_by(season, character_name) %>% 
  count(sentiment) %>%
  ungroup() %>%
  ggplot(aes(season, n, fill = sentiment)) +
  geom_col(position = "fill") +
  geom_text(aes(label = n), position = position_fill(0.5), color = "white")+
  coord_flip()+
  facet_wrap(character_name~.)+
  theme_dark()+
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
    )+
  scale_fill_manual(values = c("#EA181E", "#00B4E8"))+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))+
  labs(y = NULL,  x = "Season", fill = NULL, title = "Negative-Positive Ratio in all seasons by using bing lexicon")
```

## Total sentiment score
```{r}
install.packages('base64')

char.sent3 <-
  inner_join(
    char.tk, 
    get_sentiments("afinn"),
    by = c("word" = "word"))

char.sent3 %>% 
  group_by(season, character_name) %>% 
  summarise(total = sum(value), .groups = 'drop') %>% 
  ungroup() %>% 
  mutate(Neg = if_else(total < 0, TRUE, FALSE)) %>% 
  ggplot()+
  geom_path(aes(season, total, color = character_name), size = 1.2)+
  theme_minimal()+
  theme(legend.position = "bottom")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))+
  scale_color_manual(values = c("#EA181E", "#00B4E8", "#FABE0F", "seagreen2", "orchid", "royalblue"))+
  labs(x = "Season", color = NULL, y = "Total Sentiment Score")+
  annotation_custom(img, ymin = 350, ymax = 400, xmin = 1, xmax = 4)
```

